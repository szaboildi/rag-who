[default]
input_text_folder           = "data/raw_input_files"
input_folder_qa             = "data"
sample_qa_file              = "sample_qa.json"
relevance_score_file_prefix = "sample_qa_passage_lvl"

chunk_length                = 150
chunk_overlap               = 15

client_source               = "https://75ce65ac-3f32-4f99-9994-130310c38fc1.europe-west3-0.gcp.cloud.qdrant.io"
encoder_name                = "intfloat/e5-base"
distance_type               = "COSINE"
collection_name             = "who_guidelines"

retrieve_k_pre_rank         = 8
retrieve_k                  = 4
sparse_retriever            = "BM25"

llm_model                   = "gpt-4o-mini"
llm_temperature             = 0.4
llm_system_prompt_path      = "prompts/llm_system_prompt.txt"
llm_user_prompt_template    = "prompts/llm_user_prompt_template_haystack.txt"
QA_export_folder            = "data/rag_qa"


[not_default]
input_text_folder           = "data/raw_input_files"
input_folder_qa             = "data"
sample_qa_file              = "sample_qa.json"
relevance_score_file_prefix = "sample_qa_passage_lvl"

chunk_length                = 200
chunk_overlap               = 20

client_source               = ":memory:"
encoder_name                = "intfloat/e5-base"
distance_type               = "COSINE"
collection_name             = "who_guidelines"

retrieve_k_pre_rank         = 8
retrieve_k                  = 4
sparse_retriever            = "BM25"

llm_model                   = "gpt-4o-mini"
llm_temperature             = 0.4
llm_system_prompt_path      = "prompts/llm_system_prompt.txt"
llm_user_prompt_template    = "prompts/llm_user_prompt_template_haystack.txt"
QA_export_folder            = "data/rag_qa"
